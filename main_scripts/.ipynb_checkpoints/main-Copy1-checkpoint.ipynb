{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import any data set from nba_data folder\n",
    "path = '../nba_data/sched1819.csv'\n",
    "global nba_original\n",
    "nba_original = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data Cleaning\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df2, path):\n",
    "    #cleaning columns\n",
    "    df2 = df2[df2['Home/Neutral'] != 'Home/Neutral']\n",
    "    df2 = df2.reset_index(drop = True)\n",
    "    df = df2.copy()\n",
    "    df['HomeWin'] = np.where(df['PTS'] < df['PTS.1'], 1, 0)\n",
    "    df.rename(columns = {'Visitor/Neutral':'Away', 'Home/Neutral' : 'Home'}, inplace = True)\n",
    "    \n",
    "    #one hot encoding\n",
    "    from sklearn import preprocessing\n",
    "    dummies = pd.get_dummies(df[[\"Away\",\"Home\"]])\n",
    "    df[dummies.columns] = dummies\n",
    "    \n",
    "    #drop columns\n",
    "    df.drop(columns = ['Date', 'Start (ET)','Unnamed: 6','Unnamed: 7','Attend.','Notes', 'PTS', 'PTS.1', 'Away','Home'], inplace = True)\n",
    "    \n",
    "\n",
    "    return df, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Feature Engineering\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def win_streak(df, original):\n",
    "    #empty dictionary must be created to keep loss counts \n",
    "    team_counts = {team: 0 for team in original['Visitor/Neutral'].unique()}\n",
    "\n",
    "    for i in range(len(original)):\n",
    "        x = original.loc[i,'Visitor/Neutral']\n",
    "        y = team_counts[x]\n",
    "        df.loc[i,'Away_win_streak'] = team_counts[original.loc[i,'Visitor/Neutral']]\n",
    "        df.loc[i,'Home_win_streak'] = team_counts[original.loc[i,'Home/Neutral']]\n",
    "        if df.iloc[i,-3] == 1:\n",
    "            team_counts[original.loc[i,'Visitor/Neutral']] = 0\n",
    "            team_counts[original.loc[i,'Home/Neutral']] += 1\n",
    "        else:\n",
    "            team_counts[original.loc[i,'Visitor/Neutral']] += 1 \n",
    "            team_counts[original.loc[i,'Home/Neutral']] = 0 \n",
    "            \n",
    "    return df\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lose_streak(df, original):\n",
    "    #empty dictionary must be created to keep loss counts \n",
    "    lose_counts = {team: 0 for team in original['Visitor/Neutral'].unique()}\n",
    "    \n",
    "    for i in range(len(original)):\n",
    "        df.loc[i,'Away_lose_streak'] = lose_counts[original.loc[i,'Visitor/Neutral']]\n",
    "        df.loc[i,'Home_lose_streak'] = lose_counts[original.loc[i,'Home/Neutral']]\n",
    "        if df.loc[i,'HomeWin'] == 1:\n",
    "            lose_counts[original.loc[i,'Visitor/Neutral']] == 1\n",
    "            lose_counts[original.loc[i, 'Home/Neutral']] == 0\n",
    "        else:\n",
    "            lose_counts[original.loc[i,'Visitor/Neutral']] == 0\n",
    "            lose_counts[original.loc[i, 'Home/Neutral']] == 1\n",
    "    \n",
    "    return df \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeaway(df, original):\n",
    "    df[\"Timeaway\"] = 0\n",
    "    away_counts = {}\n",
    "    for i in original[\"Visitor/Neutral\"].unique():\n",
    "        away_counts[i] = 0\n",
    "    for i in range(len(original)):\n",
    "        away_counts[original[\"Visitor/Neutral\"][i]] +=1\n",
    "        away_counts[original[\"Home/Neutral\"][i]] = 0\n",
    "        df.iloc[i,-1] = away_counts[original[\"Visitor/Neutral\"][i]]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allstars(df, original):\n",
    "    \n",
    "    allstar_count = {}\n",
    "    for i in original[\"Visitor/Neutral\"].unique():\n",
    "        allstar_count[i] = 0\n",
    "    #West\n",
    "    allstar_count['Dallas Mavericks'] = 1\n",
    "    allstar_count['Houston Rockets'] = 2\n",
    "    allstar_count[ 'Los Angeles Clippers'] = 2\n",
    "    allstar_count['Los Angeles Lakers'] = 2\n",
    "    allstar_count['Portland Trail Blazers'] = 1\n",
    "    allstar_count['Utah Jazz'] = 1\n",
    "    allstar_count['Minnesota Timberwolves'] = 1\n",
    "    allstar_count['Denver Nuggets'] = 1\n",
    "    allstar_count['Phoenix Suns'] = 1\n",
    "\n",
    "\n",
    "    #East\n",
    "    allstar_count['Atlanta Hawks'] = 1\n",
    "    allstar_count['Boston Celtics'] = 2\n",
    "    allstar_count['Toronto Raptors'] = 1\n",
    "    allstar_count['Milwaukee Bucks'] = 2\n",
    "    allstar_count['Philadelphia 76ers'] = 2\n",
    "    allstar_count['Miami Heat'] = 2\n",
    "    allstar_count['Washington Wizards'] = 1\n",
    "    allstar_count['Indiana Pacers'] = 1\n",
    "    \n",
    "    for i in range(len(original)):\n",
    "        df.loc[i,'Away_Allstar_Count'] = allstar_count[original.loc[i,'Visitor/Neutral']]\n",
    "        df.loc[i,'Home_Allstar_Count'] = allstar_count[original.loc[i,'Home/Neutral']]\n",
    "        \n",
    "    return df\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale features before fitting to model\n",
    "def scale(features, df):\n",
    "    from sklearn import preprocessing\n",
    "    scaler = preprocessing.StandardScaler().fit(df[features])\n",
    "    scaled = scaler.transform(df[features])\n",
    "    df[features]= scaled\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nModel Fitting and Evaluation\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Model Fitting and Evaluation\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(df, model):\n",
    "    X_train = df[:984].drop(columns = \"HomeWin\")    \n",
    "    y_train = df[\"HomeWin\"][:984]\n",
    "    X_test = df[984:].drop(columns = \"HomeWin\")\n",
    "    y_test = df[\"HomeWin\"][984:]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    return accuracy_score(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fit(df):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    logistic = fit(df, LogisticRegression())\n",
    "    support_vector = fit(df, SVC(gamma='auto'))\n",
    "    rand_forest = fit(df, RandomForestClassifier(n_estimators = 100))\n",
    "    print(f'Logistic Regression: {logistic} \\n Support Vector Classifier: {support_vector} \\n Random Forest Classifier: {rand_forest} ') \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_predict(df, model,):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    logistic = fit(df, LogisticRegression())\n",
    "    support_vector = fit(df, SVC(gamma='auto'))\n",
    "    rand_forest = fit(df, RandomForestClassifier(n_estimators = 100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call Functions\n",
    "cleaned, nba_original = clean(nba_original, path)\n",
    "df_unscaled = allstars(timeaway(lose_streak(win_streak(cleaned, nba_original), nba_original),nba_original),nba_original)\n",
    "feats = df_unscaled.iloc[:,-7:].columns\n",
    "df_scaled = scale(feats, df_unscaled)\n",
    "run_fit(df_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
